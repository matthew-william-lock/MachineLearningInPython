{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "version": "2.7.17-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2,
  "kernelspec": {
   "name": "python271764bit78f88f935a2841bba395959420e40bc2",
   "display_name": "Python 2.7.17 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-af93ee88c2cd>, line 13)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-af93ee88c2cd>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    import sklearn.model_selection import train_test_split\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data.csv')\n",
    "# iloc[rows,columns] is used to reference local indexes\n",
    "X = dataset.iloc[:, :-1].values # Matrix of features. Note that range includes lower bound but does not include upper bound of '-1'\n",
    "y = dataset.iloc[:, -1].values # Matrix of features of dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['France' 44.0 72000.0]\n ['Spain' 27.0 48000.0]\n ['Germany' 30.0 54000.0]\n ['Spain' 38.0 61000.0]\n ['Germany' 40.0 nan]\n ['France' 35.0 58000.0]\n ['Spain' nan 52000.0]\n ['France' 48.0 79000.0]\n ['Germany' 50.0 83000.0]\n ['France' 37.0 67000.0]]\n['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking care of missing data\n",
    "- A viable way to deal with missing data is to delete the row of data.\n",
    "- Another option is to take the average of the data\n",
    "\n",
    "Notice the missing **salary** data for the 5th entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['France' 44.0 72000.0]\n ['Spain' 27.0 48000.0]\n ['Germany' 30.0 54000.0]\n ['Spain' 38.0 61000.0]\n ['Germany' 40.0 63777.77777777778]\n ['France' 35.0 58000.0]\n ['Spain' 38.77777777777778 52000.0]\n ['France' 48.0 79000.0]\n ['Germany' 50.0 83000.0]\n ['France' 37.0 67000.0]]\n"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# SimpleImputer(missing_values,strategy)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean') # Replace the missing value with the mean of the feature itself\n",
    "imputer.fit(X[:,1:3])   # Only expects columns with numerical values\n",
    "X[:,1:3] = imputer.transform(X[:,1:3])     # Performs transformation and replaces missing data with numeric mean, and returns the new data. Be sure only to change the affected \n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding catergorical data\n",
    "This essentially involves turning categorical strings into numerical values. We want to avoid using encoding which would lead the model to believe there is a correlation between the categories. One solution invloves One Hot Encoding.\n",
    "\n",
    "**One Hot Encoding** <br>\n",
    "Replace the categorical column with a number of columns equal to the number of unique categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1.0 0.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [0.0 1.0 0.0 30.0 54000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [0.0 1.0 0.0 40.0 63777.77777777778]\n [1.0 0.0 0.0 35.0 58000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [1.0 0.0 0.0 48.0 79000.0]\n [0.0 1.0 0.0 50.0 83000.0]\n [1.0 0.0 0.0 37.0 67000.0]]\n"
    }
   ],
   "source": [
    "# One Hot Encoding  - features\n",
    "\n",
    "# ColumnTransformer(\n",
    "#     transformers=[(typeOfTransformation,NameOfTheClassForTheTransformation,[columnsToApplyTo])],\n",
    "#     remainder = what to do with columns with no transformation\n",
    "#     )\n",
    "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder='passthrough') # 'passthrough' leaves columns as is\n",
    "X = np.array(ct.fit_transform(X)) # Fit and transform the data in one step\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0 1 0 0 1 1 0 1 0 1]\n"
    }
   ],
   "source": [
    "# Label Encoding  - dependent variable\n",
    "le =LabelEncoder()\n",
    "y = le.fit_transform(y) # No need for this to be numpy array\n",
    "\n",
    "print(y) # Binary outcome should correspond to final column of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "This is required to scale features into the same range. \n",
    "This is requried in some models to ensure that features with naturally higher numerical values do not dominate the prediction.\n",
    "- Feature scaling is not required in linear regression\n",
    "\n",
    "### Standardisation Feature Scaling\n",
    "This will generally place values all in range \\[-3:+3] <br>\n",
    "$x_{stand} = \\frac{x-\\overline{x}}{\\sigma(x)}$\n",
    "\n",
    "### Normalisation Feature Scaling\n",
    "This will place feature values in range \\[0:1] <br>\n",
    "$x_{norm} = \\frac{x-min(x)}{max(x)-min(x)}$\n",
    "\n",
    "There generally ins't a large difference in accuracy between standardisaton and normalisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 1.22474487e+00 -6.54653671e-01 -6.54653671e-01  7.58874362e-01\n   7.49473254e-01]\n [-8.16496581e-01 -6.54653671e-01  1.52752523e+00 -1.71150388e+00\n  -1.43817841e+00]\n [-8.16496581e-01  1.52752523e+00 -6.54653671e-01 -1.27555478e+00\n  -8.91265492e-01]\n [-8.16496581e-01 -6.54653671e-01  1.52752523e+00 -1.13023841e-01\n  -2.53200424e-01]\n [-8.16496581e-01  1.52752523e+00 -6.54653671e-01  1.77608893e-01\n   6.63219199e-16]\n [ 1.22474487e+00 -6.54653671e-01 -6.54653671e-01 -5.48972942e-01\n  -5.26656882e-01]\n [-8.16496581e-01 -6.54653671e-01  1.52752523e+00  0.00000000e+00\n  -1.07356980e+00]\n [ 1.22474487e+00 -6.54653671e-01 -6.54653671e-01  1.34013983e+00\n   1.38753832e+00]\n [-8.16496581e-01  1.52752523e+00 -6.54653671e-01  1.63077256e+00\n   1.75214693e+00]\n [ 1.22474487e+00 -6.54653671e-01 -6.54653671e-01 -2.58340208e-01\n   2.93712492e-01]]\n"
    }
   ],
   "source": [
    "print(X) # All the values are now in the same range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset in the Training set and Testing set\n",
    "We always make sure the testing set is seperate to prevent 'overfitting' on the training set, which causes the model to be bad at predicting new scenarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split(X matrix,y matrix,test_size= percentage of data to be in test set, random_state=0 (Optional) )\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=0)"
   ]
  }
 ]
}