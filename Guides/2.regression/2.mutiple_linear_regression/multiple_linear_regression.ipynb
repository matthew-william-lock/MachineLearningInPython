{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Multiple Linear Regression","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPhYhte6t7H4wEK4xPpDWT7"},"kernelspec":{"name":"python271764bit78f88f935a2841bba395959420e40bc2","display_name":"Python 2.7.17 64-bit"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CazISR8X_HUG","colab_type":"text"},"source":["# Multiple Linear Regression\n","Multiple linear regression takes the form of fitting to a trendline, specifically in this case a polynomial trendline. It is similat to simple linear regression, but works with many variables. "]},{"cell_type":"markdown","metadata":{},"source":["$y = b_0+b_1*x_1+b_2*x_2+...+b_n*x_n$ \n","\n","- $y$ is the Dependent Variable (DV)\n","- $x_i$ is an Independent Variable (IV)\n","- The independent variable may directly or indirectly affect the DP\n","- $b_i$ is a coefficient (coefficient can be considered to be coefficient of proportion) \n","- $b_o is the constant "]},{"cell_type":"markdown","metadata":{},"source":["**NOTE** - Assunptions of Linear Regression:\n","- Linearity\n","- Homoscedasticity\n","- Multivariate normality\n","- Independence of errors\n","- Lack of multicollinearity "]},{"cell_type":"markdown","metadata":{},"source":["## Problem Statement\n","In this guide, we want build a model predicting a companies profits based on it's expenses.\n","\n","$y = b_0+b_1*x_1+b_2*x_2+b_3*x_3+b_?*x_?$ \n","\n","- $x_1$ is the R&D Spend\n","- $x_2$ is the Admin cost\n","- $x_3$ is the Marketing cost\n","- $x_?$ is the State\n","\n","But how do we represent the state? It is categorical data! \n","<br>\n","Therefore, we replace the State with a dummy variable (see categorical encoding in data_preproccessing tools)"]},{"cell_type":"markdown","metadata":{},"source":["## Caveats of Categorical Encoding\n","If the set of States had a size of 2 (there are only two states) we could replace the State column with a single binary value. This makes sense as 0 could represent a state, and 1 the other state. This works as a 'light switch'.\n","<br>\n","\n","One might see this as potential issue with this is that the 0 value will not have a coefficient:\n","<br>\n","$b_4*0=0$\n","\n","**But**, this is accounted for in constant $b_0$\n","<br>\n","If we were to have kept two binary values instead of one, we would have created a situation where one column was directly dependent on another. Hence they would no longer be Independent Variables - This is known as the dummy variable trap.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## The P-Value\n","Before embaraking on the journey of multiple linear regression, it is imperative you understand the P-Value.\n","<br>\n","A guide on what the P-Value is can be found [here](https://www.mathbootcamps.com/what-is-a-p-value/) or [here](https://www.wikihow.com/Calculate-P-Value).\n","\n","### Definition of the P-Value:\n","The probability that, IF the null hypothesis were true, sampling variation would produce an estimate that is further from the hypothersised value than our data estimate.\n","In less formal terms, the p-value tells us how likely it is to get a result like this if the Null Hypothesis is true."]},{"cell_type":"markdown","metadata":{},"source":["## Process of constructing a model\n","When constructing a model it is important to pay attention to it's structure. Building a model based on bad information will give you a bad model.\n","There are several methods for building multiple linear regression models. These include:\n","\n","1. All-in\n","2. Backward Elimination\n","3. Forward Selection\n","4. Bidirectional Elimination\n","5. Score Comparison\n","\n","2,3,4 and can fall under stepwise regression"]},{"cell_type":"markdown","metadata":{},"source":["## 1.All-in\n","The processes of throwing all your data into the model. This is not a good idea for several reason.\n","\n","- Bad data produces a bad model\n","- Understanding and explaining correlation in the model\n","\n","When would we use this model?\n","\n","- When we have prior knowledge and know what the important data is\n","- When prepairing for Bakward Elimination\n","- When you are forced to :)"]},{"cell_type":"markdown","metadata":{},"source":["## 2.Bakward Elimination\n","\n","**Step 1**: Select a significance level to stay in the model (e.g. $SL=0.05$)\n","<br>\n","**Step 2**: Fit the full model with all possible predictors\n","<br>\n","**Step 3**: Consider the predictor with the **highest** P-Value. If $P > SL$, go to Step 4, otherwise go to FIN\n","<br>\n","**Step 4**: Remove the predictor\n","<br>\n","**Step 5**: Fit the model without this variable! Go back to Step 3\n","<br>\n","**FIN** - Your model is ready"]},{"cell_type":"markdown","metadata":{},"source":["## 3.Forward Elimination\n","\n","**Step 1**: Select a significance level to enter the model (e.g. $SL=0.05$)\n","<br>\n","**Step 2**: Fit all simple regression models $y\\sim x_n$ Select the one with the lowest P-value\n","<br>\n","**Step 3**: Keep this fariable and fit all possible models with one extra predictor added to the one(s) you already have\n","<br>\n","**Step 4**: Consider the predictor with the **lowest** P-value. If $P<SL$, go to step 3, otherwise go to FIN (and use previous model)"]},{"cell_type":"markdown","metadata":{},"source":["## 4.Bidirectional Elimination\n","\n","**Step 1**: Select a significance level to enter and a significance level to stay in the model (e.g. $SL=0.05$)\n","<br>\n","**Step 2**: Perform the next step of Forward Selection. (new variables must have $P<SL_{ENTER}$ to enter)\n","<br>\n","**Step 3**: Perform ALL STEPS of Backward Elimination. (old variables must have $P<SL_{STAY}$ to stay) Go back to Step 2. \n","<br>\n","**Step 4**: No new variables can enter and no old variables can exit"]},{"cell_type":"markdown","metadata":{},"source":["## 5.All Possible Models\n","This approach is the most resource intensive\n","\n","**Step 1**: Select a criterion of goodnesss of fit (e.g. Akaike criterion)\n","<br>\n","**Step 2**: Construct all possible regression Models : $2^N-1$ total combinations\n","<br>\n","**Step 3**: Select the model with the best criterion.\n","\n","\n","To give you an idea of how intensive this is, consider a model with 10 columns : $2^{10}-1 = 1,023$ models\n","<br>\n","This might not be a good idea for large models."]},{"cell_type":"markdown","metadata":{},"source":["# Building a Backward Elimination Model\n","We will build this model as it is efficient and effective enough for the purposes of this guide. \n","* Note: In multiple linear regression, feature scaling is not required as the coefficients will take care of this.\n","* Later guides will show you how to create a quick multiple linear regression model. Implement this check accurancy of the model instead of checking linearity of data"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pOyqYHTk_Q57"},"source":["## Importing the libraries"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# General Imoprts\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Encoding\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Splitting the data\n","from sklearn.model_selection import train_test_split\n","\n","# Linear Regression Model\n","from sklearn.linear_model import LinearRegression"]},{"cell_type":"markdown","metadata":{"id":"vgC61-ah_WIz","colab_type":"text"},"source":["## Importing the dataset\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["dataset = pd.read_csv('50_Startups.csv')\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"[[165349.2 136897.8 471784.1 'New York']\n [162597.7 151377.59 443898.53 'California']\n [153441.51 101145.55 407934.54 'Florida']\n [144372.41 118671.85 383199.62 'New York']\n [142107.34 91391.77 366168.42 'Florida']\n [131876.9 99814.71 362861.36 'New York']\n [134615.46 147198.87 127716.82 'California']\n [130298.13 145530.06 323876.68 'Florida']\n [120542.52 148718.95 311613.29 'New York']\n [123334.88 108679.17 304981.62 'California']\n [101913.08 110594.11 229160.95 'Florida']\n [100671.96 91790.61 249744.55 'California']\n [93863.75 127320.38 249839.44 'Florida']\n [91992.39 135495.07 252664.93 'California']\n [119943.24 156547.42 256512.92 'Florida']\n [114523.61 122616.84 261776.23 'New York']\n [78013.11 121597.55 264346.06 'California']\n [94657.16 145077.58 282574.31 'New York']\n [91749.16 114175.79 294919.57 'Florida']\n [86419.7 153514.11 0.0 'New York']\n [76253.86 113867.3 298664.47 'California']\n [78389.47 153773.43 299737.29 'New York']\n [73994.56 122782.75 303319.26 'Florida']\n [67532.53 105751.03 304768.73 'Florida']\n [77044.01 99281.34 140574.81 'New York']\n [64664.71 139553.16 137962.62 'California']\n [75328.87 144135.98 134050.07 'Florida']\n [72107.6 127864.55 353183.81 'New York']\n [66051.52 182645.56 118148.2 'Florida']\n [65605.48 153032.06 107138.38 'New York']\n [61994.48 115641.28 91131.24 'Florida']\n [61136.38 152701.92 88218.23 'New York']\n [63408.86 129219.61 46085.25 'California']\n [55493.95 103057.49 214634.81 'Florida']\n [46426.07 157693.92 210797.67 'California']\n [46014.02 85047.44 205517.64 'New York']\n [28663.76 127056.21 201126.82 'Florida']\n [44069.95 51283.14 197029.42 'California']\n [20229.59 65947.93 185265.1 'New York']\n [38558.51 82982.09 174999.3 'California']\n [28754.33 118546.05 172795.67 'California']\n [27892.92 84710.77 164470.71 'Florida']\n [23640.93 96189.63 148001.11 'California']\n [15505.73 127382.3 35534.17 'New York']\n [22177.74 154806.14 28334.72 'California']\n [1000.23 124153.04 1903.93 'New York']\n [1315.46 115816.21 297114.46 'Florida']\n [0.0 135426.92 0.0 'California']\n [542.05 51743.15 0.0 'New York']\n [0.0 116983.8 45173.06 'California']]\n"}],"source":["print(X)"]},{"cell_type":"markdown","metadata":{"id":"VadrvE7s_lS9","colab_type":"text"},"source":["## Encoding categorical data\n","**Note***: One of the dummy variables will be redundant"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n","X = np.array(ct.fit_transform(X))"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n [0.0 0.0 1.0 86419.7 153514.11 0.0]\n [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n [1.0 0.0 0.0 0.0 135426.92 0.0]\n [0.0 0.0 1.0 542.05 51743.15 0.0]\n [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"}],"source":["print(X)"]},{"cell_type":"markdown","metadata":{"id":"WemVnqgeA70k","colab_type":"text"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"]},{"cell_type":"markdown","metadata":{"id":"k-McZVsQBINc","colab_type":"text"},"source":["## Training the Multiple Linear Regression model on the Training set\n","- Do we need to do anything to avoid the dummy variable trap?\n","<br>\n","No! The multiple linear regression class that is imported will automatically avoid this trap.\n","- Do we need to worry about implementing the Backward Elimination process?\n","<br>\n","No! The multiple linear regression class that is imported will automatically do this for us.\n","\n","The purpose of machine learning in today's world is speed and efficiency. There is no need to reinvent the wheel if it already exists."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False)"},"metadata":{},"execution_count":16}],"source":["regressor = LinearRegression() # The model is built but not trained\n","regressor.fit(X_train,y_train) # Train the multiple linear regression model"]},{"cell_type":"markdown","metadata":{"id":"xNkXL1YQBiBT","colab_type":"text"},"source":["## Predicting the Test set results"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["y_pred = regressor.predict(X_test)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"[[103015.2  103282.38]\n [132582.28 144259.4 ]\n [132447.74 146121.95]\n [ 71976.1   77798.83]\n [178537.48 191050.39]\n [116161.24 105008.31]\n [ 67851.69  81229.06]\n [ 98791.73  97483.56]\n [113969.44 110352.25]\n [167921.07 166187.94]]\n"}],"source":["np.set_printoptions(precision=2) # Set number of decimals\n","# np.concatenate\n","print(np.concatenate( (y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)), 1 ))"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":"<matplotlib.collections.PathCollection at 0x17554e08>"},"metadata":{},"execution_count":30},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":"<Figure size 432x288 with 1 Axes>","image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (http://matplotlib.org/) -->\n<svg height=\"252.018125pt\" version=\"1.1\" viewBox=\"0 0 397.875 252.018125\" width=\"397.875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 252.018125 \nL 397.875 252.018125 \nL 397.875 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 52.375 228.14 \nL 387.175 228.14 \nL 387.175 10.7 \nL 52.375 10.7 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m79003d6711\" style=\"stroke:#ff0000;\"/>\n    </defs>\n    <g clip-path=\"url(#p640f1be2b6)\">\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"136.080251\" xlink:href=\"#m79003d6711\" y=\"155.458169\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"246.206\" xlink:href=\"#m79003d6711\" y=\"102.654615\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"251.211603\" xlink:href=\"#m79003d6711\" y=\"102.894887\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"67.593206\" xlink:href=\"#m79003d6711\" y=\"210.890602\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"371.956794\" xlink:href=\"#m79003d6711\" y=\"20.583661\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"140.718688\" xlink:href=\"#m79003d6711\" y=\"131.980782\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"76.81195\" xlink:href=\"#m79003d6711\" y=\"218.256339\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"120.495921\" xlink:href=\"#m79003d6711\" y=\"163.000819\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"155.080528\" xlink:href=\"#m79003d6711\" y=\"135.895109\"/>\n     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"305.138955\" xlink:href=\"#m79003d6711\" y=\"39.543416\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m91895abd8a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"73.508851\" xlink:href=\"#m91895abd8a\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 80000 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-38\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-30\"/>\n      </defs>\n      <g transform=\"translate(57.602601 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"127.258854\" xlink:href=\"#m91895abd8a\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100000 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-31\"/>\n      </defs>\n      <g transform=\"translate(108.171354 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"181.008858\" xlink:href=\"#m91895abd8a\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 120000 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-32\"/>\n      </defs>\n      <g transform=\"translate(161.921358 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.758862\" xlink:href=\"#m91895abd8a\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 140000 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-34\"/>\n      </defs>\n      <g transform=\"translate(215.671362 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"288.508865\" xlink:href=\"#m91895abd8a\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 160000 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-36\"/>\n      </defs>\n      <g transform=\"translate(269.421365 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-36\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"342.258869\" xlink:href=\"#m91895abd8a\" y=\"228.14\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 180000 -->\n      <g transform=\"translate(323.171369 242.738437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-38\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m5105705a45\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m5105705a45\" y=\"196.560794\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 80000 -->\n      <g transform=\"translate(13.5625 200.360013)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m5105705a45\" y=\"160.842988\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 100000 -->\n      <g transform=\"translate(7.2 164.642207)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m5105705a45\" y=\"125.125182\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 120000 -->\n      <g transform=\"translate(7.2 128.924401)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m5105705a45\" y=\"89.407376\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 140000 -->\n      <g transform=\"translate(7.2 93.206595)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m5105705a45\" y=\"53.689571\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 160000 -->\n      <g transform=\"translate(7.2 57.488789)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-36\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.375\" xlink:href=\"#m5105705a45\" y=\"17.971765\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 180000 -->\n      <g transform=\"translate(7.2 21.770983)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-38\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"318.115234\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 52.375 228.14 \nL 52.375 10.7 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 387.175 228.14 \nL 387.175 10.7 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 52.375 228.14 \nL 387.175 228.14 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 52.375 10.7 \nL 387.175 10.7 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p640f1be2b6\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"52.375\" y=\"10.7\"/>\n  </clipPath>\n </defs>\n</svg>\n"},"metadata":{"needs_background":"light"}}],"source":["plt.figure()\n","plt.scatter(y_test,y_pred,color=\"red\")"]},{"cell_type":"markdown","metadata":{},"source":["## Implementations of Automatic Backward Elimination"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 1 \n","\n","import statsmodels.formula.api as sm\n","def backwardElimination(x, sl):\n","    numVars = len(x[0])\n","    for i in range(0, numVars):\n","        regressor_OLS = sm.OLS(y, x).fit()\n","        maxVar = max(regressor_OLS.pvalues).astype(float)\n","        if maxVar > sl:\n","            for j in range(0, numVars - i):\n","                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n","                    x = np.delete(x, j, 1)\n","    regressor_OLS.summary()\n","    return x\n"," \n","SL = 0.05\n","X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n","X_Modeled = backwardElimination(X_opt, SL)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 2 \n","\n","import statsmodels.formula.api as sm\n","def backwardElimination(x, SL):\n","    numVars = len(x[0])\n","    temp = np.zeros((50,6)).astype(int)\n","    for i in range(0, numVars):\n","        regressor_OLS = sm.OLS(y, x).fit()\n","        maxVar = max(regressor_OLS.pvalues).astype(float)\n","        adjR_before = regressor_OLS.rsquared_adj.astype(float)\n","        if maxVar > SL:\n","            for j in range(0, numVars - i):\n","                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n","                    temp[:,j] = x[:, j]\n","                    x = np.delete(x, j, 1)\n","                    tmp_regressor = sm.OLS(y, x).fit()\n","                    adjR_after = tmp_regressor.rsquared_adj.astype(float)\n","                    if (adjR_before >= adjR_after):\n","                        x_rollback = np.hstack((x, temp[:,[0,j]]))\n","                        x_rollback = np.delete(x_rollback, j, 1)\n","                        print (regressor_OLS.summary())\n","                        return x_rollback\n","                    else:\n","                        continue\n","    regressor_OLS.summary()\n","    return x\n"," \n","SL = 0.05\n","X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n","X_Modeled = backwardElimination(X_opt, SL)"]}]}